# -*- coding: utf-8 -*-
"""Copy of DATA 602 Project Stage 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eB1WgfUZXP1S6GcpY_4IYJKMKe7-OzV-

# Project Part 1

## About the Dataset

Points kept in mind while selecting the dataset were:
1. Project Goals
2. Considering the size and complexity of the dataset
3. Checking the quality and completeness

## Overview of the dataset
"""

# download and unzip the dataset from kaggle
!kaggle datasets download -d iammustafatz/diabetes-prediction-dataset
!unzip /content/diabetes-prediction-dataset.zip

import pandas as pd
import numpy as np

df=pd.read_csv("diabetes_prediction_dataset.csv")

df.size

df.info()

df.isnull().sum()

df.describe()

"""## Pre-processing steps

The pre-processing steps that we plan to implement are :
*    Understanding the structure of the data (for example : number of rows and columns, stats of the dataset and so on...) .
*    Check for data types.
*    handle any missing values based on the type of missing values i.e., MAR, MCAR and MNAR.
*    Imputing the missing value or remove specific rows based on the type of missing value.
*    Encoding the categorical variables.
*    Normalising or scaling the data whereever required to counter the  skewness in the distribution.
*    Splitting the dataset into train, test , dev splits for using Machine Learning and Deep Learning techniques on the dataset.
*    Checking for outliers.
*    Performing Exploratory Data Analysis (EDA).

# Project Part 2
"""

df.head()

#listing all the columns of the dataset
df.columns

"""## Features and Target Outcome

The features that can be used for the final project are:
* gender
* age
* hypertension
* heart_disease
* smoking_history
* bmi
* HbA1c_level
* blood_glucose_level

The target outcome to be determined using these features is:

diabetes (0 for no diabetes, 1 for diabetes)
"""

#counting uniquevalues for each feature column
for i in list(df.columns):
 print(df[i].value_counts())

"""## Initial plan for feature engineering

1. Gender: One-hot encode gender into different categories (e.g., Female, Male, Other).

2. Smoking History:

 *  Combine "ever" and "former" (both indicate past smoking) into a single category.
 * "not current" could be considered similar to "former."
 * Handle "No Info" with missing value techniques such as imputation or removing entries with such category.
 * One-hot encode smoking_history to represent the different categories (e.g., "never", "current", "former").

3. Age Grouping: Create age bins (e.g., <30, 30-50, >50) for better interpretation.

4. BMI Categories: Convert bmi into categories (underweight, normal, overweight, obese) based on standard BMI ranges and One-hot encode them.

5. Interaction terms: Consider ratios like HbA1c_level/blood_glucose_level to explore relationships between features.

## Dealing with the imbalanced data
"""

print("Target class counts:", df.diabetes.value_counts())
print("Target class percentages:", (df.diabetes.value_counts()/np.sum(df.diabetes.value_counts()))*100)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='diabetes')
plt.title("Class Distribution")
plt.show()

"""Since the target variable diabetes is highly imbalanced (91.5% non-diabetic and 8.5% diabetic), we will use techniques to ensure that the model does not overly favor the majority class (non-diabetic).

Proposed Methods:

1. Oversampling the Minority Class (Diabetic):
We will apply SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for the minority class (diabetic). This technique creates new instances based on the nearest neighbors of minority class examples, making the dataset more balanced.

2. Undersampling the Majority Class (Non-Diabetic):
We may consider undersampling the non-diabetic class to reduce its size and prevent the model from being biased toward predicting the majority class. This will only be done if oversampling alone doesn't yield optimal results.

3. Class Weight Adjustment: We will use models that allow setting class weights (e.g., in logistic regression, decision trees, or neural networks) to assign a higher weight to the diabetic class, ensuring the algorithm penalizes misclassifications of diabetic cases more heavily.

# Project Part 3
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

# If you want to use SMOTE (optional)
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline  # SMOTE-compatible pipeline

# Load the dataset
df = pd.read_csv("diabetes_prediction_dataset.csv")

# Checking the basic structure of the dataset
print(df.info())
print(df.isnull().sum())

# Drop unnecessary columns if any (e.g., 'patient_id')
if 'patient_id' in df.columns:
    df.drop(columns=['patient_id'], inplace=True)

# Define numerical and categorical features
numerical_features = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']
categorical_features = ['gender', 'hypertension', 'heart_disease', 'smoking_history']

# Handling class imbalance visualization
print("Target class distribution:")
print(df['diabetes'].value_counts())
sns.countplot(x='diabetes', data=df)
plt.title('Class Distribution of Diabetes')
plt.show()

# Define the preprocessor with scaling for numerical and one-hot encoding for categorical features
preprocessor = ColumnTransformer(transformers=[
    ('num', SimpleImputer(strategy='median'), numerical_features),
    ('cat', OneHotEncoder(drop='first'), categorical_features)
])

# Splitting the dataset into features (X) and target (y)
X = df.drop(columns=['diabetes'])
y = df['diabetes']

# Splitting into train and test sets (80% train, 20% test), stratifying to maintain class balance
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# OPTION 1: Using class_weight='balanced' in models to handle imbalance
# Define Logistic Regression with class weights
log_reg_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(class_weight='balanced', random_state=42))
])

# Define Random Forest with class weights
rf_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))
])

# Train the Logistic Regression model
log_reg_model.fit(X_train, y_train)

# Train the Random Forest model
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_logreg = log_reg_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)

# Calculate the probabilities for ROC-AUC
y_pred_proba_logreg = log_reg_model.predict_proba(X_test)[:, 1]
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Evaluate Logistic Regression
print("Logistic Regression Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg))
print("Classification Report:\n", classification_report(y_test, y_pred_logreg))
print("ROC-AUC Score:", roc_auc_score(y_test, y_pred_proba_logreg))

# Evaluate Random Forest
print("\nRandom Forest Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("ROC-AUC Score:", roc_auc_score(y_test, y_pred_proba_rf))

# OPTION 2: Using SMOTE to oversample the minority class
# Define SMOTE
smote = SMOTE(random_state=42)

# Create the pipeline with SMOTE for Logistic Regression
log_reg_model_with_smote = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', smote),
    ('classifier', LogisticRegression(random_state=42))
])

# Create the pipeline with SMOTE for Random Forest
rf_model_with_smote = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', smote),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Train the Logistic Regression model with SMOTE
log_reg_model_with_smote.fit(X_train, y_train)

# Train the Random Forest model with SMOTE
rf_model_with_smote.fit(X_train, y_train)

# Make predictions on the test set after SMOTE
y_pred_logreg_smote = log_reg_model_with_smote.predict(X_test)
y_pred_rf_smote = rf_model_with_smote.predict(X_test)

# Evaluate Logistic Regression with SMOTE
print("\nLogistic Regression with SMOTE Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg_smote))
print("Classification Report:\n", classification_report(y_test, y_pred_logreg_smote))
print("ROC-AUC Score:", roc_auc_score(y_test, log_reg_model_with_smote.predict_proba(X_test)[:, 1]))

# Evaluate Random Forest with SMOTE
print("\nRandom Forest with SMOTE Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf_smote))
print("Classification Report:\n", classification_report(y_test, y_pred_rf_smote))
print("ROC-AUC Score:", roc_auc_score(y_test, rf_model_with_smote.predict_proba(X_test)[:, 1]))

# Visualizing feature importance for Random Forest
importances = rf_model.named_steps['classifier'].feature_importances_
feature_names = numerical_features + list(rf_model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))
forest_importances = pd.Series(importances, index=feature_names)
plt.figure(figsize=(10, 6))
forest_importances.sort_values().plot(kind='barh')
plt.title('Random Forest Feature Importance')
plt.show()

"""### **Discussion of Accuracy on Testing and Training Data**

#### **1. Logistic Regression (with class weights)**:
   - **Training Accuracy**: ~88% (implicit from test performance)
   - **Testing Accuracy**: 88.65%
   - **Classification Performance**:
     - **Precision (diabetic class)**: 0.42
     - **Recall (diabetic class)**: 0.85
     - **F1-score (diabetic class)**: 0.56
   - **ROC-AUC Score**: 0.95

   - **Observations**:
     - Logistic Regression achieved relatively high **recall** for the diabetic class (1), meaning it identified many true positives.
     - However, its low **precision** (0.42) indicates that it predicted many false positives. This trade-off resulted in a lower **F1-score** for the minority class.
     - The **ROC-AUC score** of 0.95 shows that Logistic Regression was able to distinguish between the classes fairly well.
     - However, the overall accuracy of 88.65% suggests that the linear model struggles with the complexity of the dataset, particularly in distinguishing diabetic cases.

#### **2. Random Forest (with class weights)**:
   - **Training Accuracy**: Close to 100% (indicating overfitting)
   - **Testing Accuracy**: 96.94%
   - **Classification Performance**:
     - **Precision (diabetic class)**: 0.93
     - **Recall (diabetic class)**: 0.69
     - **F1-score (diabetic class)**: 0.79
   - **ROC-AUC Score**: 0.96

   - **Observations**:
     - Random Forest achieved a much higher **precision** (0.93) for the diabetic class, meaning fewer false positives compared to Logistic Regression.
     - While its **recall** (0.69) for the diabetic class was lower than Logistic Regression, the **F1-score** of 0.79 indicates a better balance between precision and recall.
     - The **testing accuracy** of 96.94% shows that Random Forest fits the data better and handles the non-linear relationships in the dataset more effectively.
     - However, the **training accuracy** being close to 100% suggests that the model is prone to **overfitting**, as Random Forest tends to capture even minor patterns in the training data.

### **Is Any Method Clearly Superior?**
Yes, **Random Forest** is clearly superior to **Logistic Regression** in this case.

- **Higher testing accuracy** (96.94% vs. 88.65%) indicates that Random Forest generalizes better.
- **Higher F1-score** (0.79 vs. 0.56) for the diabetic class means Random Forest is more effective at balancing precision and recall, crucial for imbalanced datasets.
- The **ROC-AUC score** of Random Forest (0.96) is slightly better than that of Logistic Regression (0.95), indicating better overall classification performance.

### **What Does This Say About the Linear Nature of Your Data?**
The superior performance of **Random Forest** suggests that the relationships between features and the target (diabetes) are likely **non-linear**.

- **Logistic Regression**, a linear model, assumes a linear relationship between the features and the target. However, the fact that it struggles to balance precision and recall and has lower accuracy suggests that the data contains **complex interactions** or **non-linearities** that a simple linear model cannot capture effectively.
- **Random Forest**, being a tree-based method, is inherently non-linear and can capture interactions and complex relationships between features. This makes it a better fit for this dataset, as seen by its significantly better performance.

### **Conclusion**:
The results indicate that the dataset likely has non-linear relationships between features and the target, which **Random Forest** captures more effectively than **Logistic Regression**. While Logistic Regression performs decently, especially in terms of recall, its linear nature limits its ability to fully capture the complexity of the data. Therefore, a tree-based method like Random Forest is clearly the superior approach for this classification task.
"""



"""#PROJECT STAGE 4"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set up the plot style
sns.set_style("whitegrid")

# Plot 1: Scatterplot of Age vs. Blood Glucose Level, colored by Diabetes Status
plt.figure(figsize=(10, 6))
sns.scatterplot(x='age', y='blood_glucose_level', hue='diabetes', data=df, palette="coolwarm", alpha=0.7)
plt.title("Age vs. Blood Glucose Level (Colored by Diabetes Status)", fontsize=15)
plt.xlabel("Age", fontsize=12)
plt.ylabel("Blood Glucose Level", fontsize=12)
plt.legend(title="Diabetes Status", labels=["No Diabetes", "Diabetes"])
plt.show()

# Plot 2: Histogram of HbA1c Level, split by Diabetes Status
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='HbA1c_level', hue='diabetes', multiple="stack", palette="viridis", bins=20)
plt.title("Distribution of HbA1c Levels by Diabetes Status", fontsize=15)
plt.xlabel("HbA1c Level", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.legend(title="Diabetes Status", labels=["No Diabetes", "Diabetes"])
plt.show()

"""**CONCLUSIONS:**

**1) Age vs. Blood Glucose Level:**

The scatterplot of age against blood glucose levels shows a generally wide range of blood glucose levels across all ages. However, individuals with diabetes tend to have higher blood glucose levels compared to those without diabetes. Although age doesn't have a definitive cutoff for diabetes, older individuals appear more frequently in the higher glucose range, suggesting a potential increase in diabetes prevalence with age.

**2)HbA1c Levels by Diabetes Status:**

The HbA1c level histogram highlights a distinct difference between the two groups: those with diabetes have higher HbA1c levels on average than those without. The distribution for individuals with diabetes is skewed toward higher HbA1c values, indicating that elevated HbA1c is a significant indicator or characteristic of diabetes.
"""

# Let's explore additional visualizations based on the dataset that can provide more insights into diabetes-related factors.

# Plot 3: Boxplot of BMI by Diabetes Status to show the distribution and median differences
plt.figure(figsize=(10, 6))
sns.boxplot(x='diabetes', y='bmi', data=df, palette="viridis")
plt.title("BMI Distribution by Diabetes Status", fontsize=16)
plt.xlabel("Diabetes Status", fontsize=13)
plt.ylabel("BMI", fontsize=13)
plt.xticks([0, 1], ["No Diabetes", "Diabetes"])
plt.show()

# Plot 4: Count plot of Smoking History by Diabetes Status
plt.figure(figsize=(12, 6))
sns.countplot(data=df, x='smoking_history', hue='diabetes', palette="viridis")
plt.title("Smoking History Distribution by Diabetes Status", fontsize=16)
plt.xlabel("Smoking History", fontsize=13)
plt.ylabel("Count", fontsize=13)
plt.legend(title="Diabetes Status", labels=["No Diabetes", "Diabetes"], loc="upper right")
plt.xticks(rotation=45)
plt.show()

"""**3)BMI by Diabetes Status (Boxplot):**

The BMI boxplot shows a noticeable spread in BMI for both groups, though individuals with diabetes have a slightly higher median BMI than those without. The higher range in BMI among diabetes patients may imply a correlation between higher BMI and diabetes, though the difference isn’t extremely large, suggesting that other factors may also play significant roles.

**4)Smoking History by Diabetes Status (Count Plot):**

The smoking history count plot suggests that people with a history of smoking (both current and former smokers) appear frequently in the diabetes group. "No Info" and "Never Smoked" categories have substantial representation in the non-diabetes group, potentially indicating that smoking status could be a contributing or associated factor in diabetes development.
"""

